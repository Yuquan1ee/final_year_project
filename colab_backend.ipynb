{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Image Editor - Backend on Colab\n",
    "\n",
    "This notebook runs the FastAPI backend for the Diffusion Image Editor project.\n",
    "\n",
    "**Setup:**\n",
    "1. Runtime > Change runtime type > Select **T4 GPU** (or better)\n",
    "2. Run all cells in order\n",
    "3. Copy the ngrok URL and paste it in your frontend `.env` file\n",
    "\n",
    "**VRAM Requirements:**\n",
    "- SD Inpainting: 5-7 GB\n",
    "- SDXL Inpainting: 10-12 GB\n",
    "- CodeFormer/GFPGAN: 2-4 GB\n",
    "- Real-ESRGAN: 2-6 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Clone Repository\n\n**If your repo is private**, you need a GitHub Personal Access Token:\n1. Go to https://github.com/settings/tokens\n2. Generate new token (classic) with `repo` scope\n3. Paste it in the cell below\n\n**If your repo is public**, leave `GITHUB_TOKEN` empty."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/Yuquan1ee/final_year_project.git\n",
    "%cd final_year_project/backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install backend dependencies from requirements.txt\n!pip install -q -r requirements.txt\n\n# Install additional packages for Colab (ngrok tunnel)\n!pip install -q pyngrok nest-asyncio"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup ngrok\n",
    "\n",
    "You need an ngrok authtoken to expose the server publicly.\n",
    "\n",
    "1. Create a free account at https://ngrok.com/\n",
    "2. Get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "3. Paste it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your ngrok authtoken here\n",
    "NGROK_AUTHTOKEN = \"\"  # <-- Paste your ngrok authtoken here\n",
    "\n",
    "if not NGROK_AUTHTOKEN:\n",
    "    print(\"WARNING: No ngrok authtoken provided!\")\n",
    "    print(\"Get your free authtoken at: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "else:\n",
    "    print(\"ngrok authtoken configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 4.5 HuggingFace Token (Optional)\n\n**Required only if you want to use gated models like FLUX.1-Fill.**\n\n1. Accept the model license at: https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev\n2. Get your token from: https://huggingface.co/settings/tokens\n3. Paste it below",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\n\n# Enter your HuggingFace token here (required for FLUX.1-Fill)\nHF_TOKEN = \"\"  # <-- Paste your HuggingFace token here (starts with hf_...)\n\nif HF_TOKEN:\n    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n    print(\"HuggingFace token configured!\")\n    print(\"You can now use gated models like FLUX.1-Fill\")\nelse:\n    print(\"No HuggingFace token provided.\")\n    print(\"You can still use: SD Inpainting, SDXL Inpainting, Kandinsky\")\n    print(\"For FLUX.1-Fill, get your token at: https://huggingface.co/settings/tokens\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start the Server\n",
    "\n",
    "This cell will:\n",
    "1. Start ngrok tunnel on port 8000\n",
    "2. Print the public URL (copy this for your frontend)\n",
    "3. Start the FastAPI server\n",
    "\n",
    "**Note:** The first request will be slow as models are loaded into GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import nest_asyncio\nfrom pyngrok import ngrok\nimport uvicorn\nimport asyncio\n\n# Allow nested event loops (required for Colab)\nnest_asyncio.apply()\n\n# Set ngrok authtoken\nif NGROK_AUTHTOKEN:\n    ngrok.set_auth_token(NGROK_AUTHTOKEN)\n\n# Start ngrok tunnel\npublic_url = ngrok.connect(8000)\nprint(\"=\" * 60)\nprint(f\"ngrok tunnel established!\")\nprint(f\"\")\nprint(f\"PUBLIC URL: {public_url.public_url}\")\nprint(f\"\")\nprint(f\"Copy this URL and set it in your frontend/.env file:\")\nprint(f'VITE_API_URL={public_url.public_url}')\nprint(f\"\")\nprint(f\"Then restart your frontend: npm run dev\")\nprint(\"=\" * 60)\n\n# Import the FastAPI app\nimport sys\nsys.path.insert(0, '/content/final_year_project/backend')\n\nfrom app.main import app\n\n# Run uvicorn with nest_asyncio compatibility\nconfig = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\nserver = uvicorn.Server(config)\nawait server.serve()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### ngrok errors\n",
    "- Make sure you entered a valid authtoken\n",
    "- Free ngrok accounts have limits (1 tunnel at a time)\n",
    "- If you get \"ERR_NGROK_108\", close other ngrok tunnels\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "- Use smaller models (SD instead of SDXL)\n",
    "- Restart runtime and try again\n",
    "\n",
    "### Slow first request\n",
    "- Models are downloaded and loaded on first use\n",
    "- SD Inpainting: ~2GB download, 30-60s load time\n",
    "- Subsequent requests are fast\n",
    "\n",
    "### Connection refused\n",
    "- Wait for \"Uvicorn running on http://0.0.0.0:8000\" message\n",
    "- Check that ngrok URL is correct in frontend .env\n",
    "- Make sure frontend is rebuilt after changing .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Run without ngrok (for testing)\n",
    "\n",
    "If you just want to test the API without a frontend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test health endpoint\n",
    "import requests\n",
    "\n",
    "# Use the ngrok URL or localhost\n",
    "API_URL = str(public_url) if 'public_url' in dir() else \"http://localhost:8000\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/api/health\")\n",
    "    print(\"Health check response:\")\n",
    "    print(response.json())\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure the server is running (cell 5)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}